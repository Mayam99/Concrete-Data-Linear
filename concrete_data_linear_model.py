# -*- coding: utf-8 -*-
"""Concrete_Data_Linear_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NbI4Q1v8M-yMlcaOUm3hafzfoqVd5lgP

##Step 1: Understand the Problem and Data

Concrete is the most widely used construction material globally, and its compressive strength is a critical indicator of structural durability and load-bearing capacity. Understanding the factors that influence concrete strength—such as cement composition, water-cement ratio, aggregate properties, and curing time—is essential for engineers and architects to design safer, more cost-effective structures.


This analysis utilizes a dataset from Kaggle (e.g., Concrete Compressive Strength) containing key variables like:

* Cement content (kg/m³)

* Blast furnace slag, Fly ash (supplementary materials)

* Water, Superplasticizer (workability agents)

* Coarse/Fine aggregate ratios

* Curing age (days)

* Target: Compressive strength (MPa, megapascals)

The primary objective is to develop a linear regression model that predicts compressive strength based on these input features. By quantifying the relationship between mix proportions and strength, this project aims to:

1. Identify the most influential factors in concrete performance.

2. Provide actionable insights for optimizing material usage.

3. Establish a baseline predictive model for further refinement (e.g., with regularization or nonlinear techniques).

This report follows a structured approach: data preprocessing, exploratory analysis, linear regression modeling, and validation, with emphasis on interpreting coefficients and evaluating practical implications for the construction industry.

## Step 2: Load and Explore the Data
"""

# Importing Necessary Libraries
import numpy as np # Numerical Computations
import pandas as pd # Data Manipulation
import seaborn as sns # Statistical Graphics
import matplotlib.pyplot as plt  # Plotting

df = pd.read_csv('concrete_data.csv') # Reading the data from the CSV file named '50_Startups.csv' and stores it in a pandas DataFrame named df.

df.head() # Displays the first 5 rows of the DataFrame df, allowing you to quickly inspect the data.

df.info() # Prints a concise summary of the DataFrame df, including data types, non-null values, and memory usage.

df.describe() # Generates descriptive statistics of the DataFrame's numerical columns, like mean, standard deviation, and quartiles.

df.isnull().sum() # Calculates and displays the number of missing (null) values in each column of the DataFrame df.

df.duplicated().sum() # Returns a boolean Series indicating whether each row in the DataFrame df is a duplicate of a previous row.

df = df.drop_duplicates() # Removes duplicate rows from the DataFrame df and updates df with the result.

df.duplicated().sum()

# Visualize Distribution
plt.figure(figsize=(12,6))
sns.histplot(df['Strength'], kde=True)
plt.title('Distribution of profit')
plt.show()

"""The histogram shows the distribution of concrete strength. Most of the concrete samples have a strength between 30 and 40 MPa (which is like the average strength). There are some samples with much higher strength, but they are less common. Overall, the strength values are spread out, but not too extremely."""

# Correlation Matrix
plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""The heatmap shows how strongly different factors in concrete are related to each other.

* Darker red colors indicate a strong positive relationship. This means as one factor increases, the other tends to increase as well. For example, Cement and Strength have a dark red color suggesting that as the amount of cement increases, the strength of the concrete also tends to increase.

* Darker blue colors indicate a strong negative relationship. This means as one factor increases, the other tends to decrease. For example, Water and Strength have a dark blue color, indicating that more water in the mix generally leads to lower concrete strength.
Lighter colors (close to white) suggest a weak or no relationship between the factors.

* Cement content has a strong positive correlation with strength.
* Water content has a strong negative correlation with strength.
* Age has a moderate positive correlation with strength.
* Superplasticizer has a weak positive correlation with strength.
* Other factors show varying degrees of correlation with strength
"""

# Pair Plot for Numeric Variables
sns.pairplot(df[['Cement', 'Blast Furnace Slag', 'Fly Ash',	'Water',	'Superplasticizer',	'Coarse Aggregate',	'Fine Aggregate',	'Age',	'Strength']])
plt.show()

#creating interaction term
df['Cement_Water_Interaction'] = df['Cement'] * df['Water']

#  creating polynomial feature
df['Age_Squared'] = df['Age'] **2

"""# Step 5: Prepare Data for Modeling"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Defining feature and target
X = df.drop('Strength', axis=1)
y = df['Strength']

# Split the data
x_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)

# Scale numberical features
scaler = StandardScaler()
cols = ['Cement', 'Blast Furnace Slag', 'Fly Ash',	'Water',	'Superplasticizer',	'Coarse Aggregate',	'Fine Aggregate',	'Age']
x_train[cols] = scaler.fit_transform(x_train[cols])
X_test[cols] = scaler.transform(X_test[cols])

"""##Step 6: Build and Train the Linear Regression Model"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Initilize and train model
lr = LinearRegression()
lr.fit(x_train, y_train)

# Making Predictions
y_pred = lr.predict(X_test)

# calculating metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Mean Absolute Erro:{mae:.2f}")
print(f"R-Squared:{r2:.2f}")

# Residual Plot
residuals = y_test - y_pred
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residuals plot')
plt.show()

"""Randomly scattered points: If the points in the residual plot are randomly scattered around the horizontal line, it suggests that our model is doing a good job of capturing the underlying patterns in the data and that there are no obvious systematic errors."""